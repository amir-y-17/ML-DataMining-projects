# گزارش پروژه  
## محاسبه ماتریس‌های فاصله، همبستگی و آنتروپی

---

## 1. مقدمه

هدف این پروژه پیاده‌سازی چهار عمل اصلی تحلیل داده بر روی یک دیتاست عددی است.  
تمام محاسبات به‌صورت **دستی** و بدون توابع آماده انجام شده‌اند  
(به‌جز معکوس‌گیری ماتریس که مجاز بود).

عملیات انجام‌شده:

1. ماتریس فاصله اقلیدسی  
2. ماتریس فاصله ماهالانوبیس  
3. ماتریس همبستگی بین ویژگی‌ها  
4. آنتروپی هر ویژگی

---

## 2. ساختار پروژه

project/
│
├── data/
│ └── dataset.xlsx
│
├── src/
│ ├── io_utils.py
│ ├── euclidean.py
│ ├── mahalanobis.py
│ ├── covariance.py
│ ├── correlation.py
│ ├── entropy.py
│
├── main.py
└── report.md
└── requirements.txt


---

## 3. خواندن داده‌ها (io_utils.py)

- داده از فایل Excel بدون هدر خوانده می‌شود.  
- داده باید کاملاً عددی باشد.  
- هیچ مقدار گمشده (NaN) نباید وجود داشته باشد.  
- داده پس از خواندن به آرایه NumPy تبدیل می‌شود.  

---

## 4. فاصله اقلیدسی (Euclidean Distance)

### 4.1 تعریف

\[
d(x,y) = \sqrt{\sum (x_i - y_i)^2}
\]

### 4.2 نکات پیاده‌سازی

- محاسبه اختلاف ویژگی‌ها به صورت دستی انجام شد.  
- مجموع مربعات اختلاف‌ها محاسبه شد.  
- ریشه دوم مقدار نهایی گرفته شد.  
- ماتریس فاصله متقارن ساخته شد (d[i,j] = d[j,i]).  
- هیچ تابع آماده مانند `np.linalg.norm` استفاده نشده است.

---

## 5. فاصله ماهالانوبیس (Mahalanobis Distance)

### 5.1 دلیل استفاده

فاصله اقلیدسی مشکلاتی دارد:

- مقیاس ویژگی‌ها را در نظر نمی‌گیرد.  
- وابستگی (کوواریانس) بین ویژگی‌ها را نادیده می‌گیرد.  
- فرض می‌کند داده‌ها در همه محورها پراکندگی برابر دارند.  

ماهالانوبیس این مشکلات را رفع می‌کند.

### 5.2 فرمول اصلی

\[
D_M(x,y)=\sqrt{(x-y)^T \; \Sigma^{-1} \; (x-y)}
\]

### 5.3 مراحل پیاده‌سازی

1. محاسبه میانگین هر ویژگی  
2. مرکزدهی داده‌ها  
3. محاسبه ماتریس کوواریانس به صورت دستی  
4. گرفتن معکوس ماتریس کوواریانس (تنها تابع آماده مجاز)  
5. محاسبه اختلاف بین نقاط  
6. اعمال ضرب ماتریسی (x-y)^T Σ⁻¹ (x-y)  
7. گرفتن ریشه دوم  
8. ساخت ماتریس فاصله به شکل متقارن  

### نکته مهم

معکوس ماتریس کوواریانس فقط یک‌بار محاسبه می‌شود → افزایش کارایی.

---

## 6. ماتریس همبستگی ویژگی‌ها (Correlation Matrix)

### 6.1 تعریف

\[
corr(i,j)=\frac{\sum (x_i-\bar{x_i})(x_j-\bar{x_j})}{(n-1)s_i s_j}
\]

که در آن:

- \( \bar{x} \): میانگین  
- \( s \): انحراف معیار  
- ماتریس خروجی d×d و متقارن است.

### 6.2 پیاده‌سازی

- میانگین‌ها دستی محاسبه شدند.  
- انحراف معیار هر ویژگی نیز دستی محاسبه شد.  
- فرمول پیرسون بدون هیچ تابع آماده اعمال شد.  
- ماتریس همبستگی بین تمام ویژگی‌ها ساخته شد.

---

## 7. آنتروپی ویژگی‌ها (Entropy)

### 7.1 تعریف

\[
H(X) = -\sum p(x)\log_2 p(x)
\]

### 7.2 مشکل داده‌های پیوسته

آنتروپی برای داده‌های **گسسته** تعریف شده،  
بنابراین لازم است داده‌های عددی را **به چند بازه (bins)** تقسیم کنیم.

### 7.3 مراحل پیاده‌سازی

1. تعیین min و max هر ویژگی  
2. تقسیم ویژگی به num_bins بخش  
3. شمارش تعداد داده در هر bin  
4. تبدیل شمارش‌ها به احتمال  
5. اعمال فرمول شانون به صورت دستی  
6. محاسبه آنتروپی برای هر ویژگی مستقل

---

## 8. نتیجه‌گیری

این پروژه شامل پیاده‌سازی کامل و دستی موارد زیر بود:

- محاسبه فاصله اقلیدسی  
- محاسبه فاصله ماهالانوبیس  
- محاسبه ماتریس همبستگی  
- محاسبه آنتروپی  

نکات مهم:

- تمام محاسبات پایه‌ای به صورت دستی نوشته شده‌اند.  
- معکوس ماتریس تنها تابع آماده مورد استفاده بود.  

---

# پایان گزارش
